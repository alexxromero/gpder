{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Experimental Design\n",
    "\n",
    "This demo shows how to use the GPUncertaintyOptimizer class to efficiently obtain new samples that will decrease the predictive uncertainty of a GP model.\n",
    "\n",
    "As a test case, we use the GaussianProcessRegressor class to calculate the efficiency of three-jet events with MET < 50 GeV.\n",
    "\n",
    "The following nuisance parameters are considered:\n",
    "- $\\nu_{J1in}$: Jet energy scale of the leading jet, $J_1$, when |$\\eta_1$| < 1.\n",
    "- $\\nu_{J1out}$: Jet energy scale of the leading jet, $J_1$, when |$\\eta_1$| >= 1.\n",
    "- $\\nu_{J23in}$: Jet energy scale of the two softer jets, $J_2$ and $J_3$, when |average($\\eta_2$, $\\eta_3$)| < 1.\n",
    "- $\\nu_{J23out}$: Jet energy scale of the two softer jets, $J_2$ and $J_3$, when |average($\\eta_2$, $\\eta_3$)| >= 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import gpder\n",
    "from gpder.gaussian_process import GaussianProcessRegressor\n",
    "from gpder.gaussian_process.kernels import RegularKernel, DerivativeKernel\n",
    "from gpder.bayes import GPUncertaintyOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the dataset failed. Please download the dataset manually from zenodo. DOI: 10.5281/zenodo.10971439\n",
      "Shape of the dataset: (30000, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "from utils import download_dataset, load_dataset\n",
    "\n",
    "# Downloading the dataset from zenodo.\n",
    "# By default, the h5df file is saved in the current directory.\n",
    "download_dataset()\n",
    "threeM = load_dataset()\n",
    "\n",
    "# The dataset consists of 30000 events, each with three jets.\n",
    "# For each jet, the three-momenta (pT, eta, phi) are saved in descending pT-order.\n",
    "print(\"Shape of the dataset:\", threeM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that calculates the efficiency with respect to the two nuisance\n",
    "# See hep_functions.py for more details\n",
    "from hep_functions import efficiency\n",
    "\n",
    "\n",
    "def efficiency_events(X, threeM=threeM):\n",
    "    # Simplifying the input\n",
    "    return efficiency(X, threeM)\n",
    "\n",
    "\n",
    "# And the function that calculates the gradient of the efficiency\n",
    "# To improve numerical stability, we smooth out the gradients by setting the\n",
    "# parameter a=1/10\n",
    "from hep_functions import der_efficiency\n",
    "\n",
    "\n",
    "def der_efficiency_events_sigmoid10(X, threeM=threeM):\n",
    "    # Simplifying the input\n",
    "    return der_efficiency(X, threeM, a=1 / 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular GP regression\n",
    "\n",
    "The regular GP used in the regular_GP_regression notebook has nine training samples. Here, we use the BED strategy to select 30 new training samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- test dataset ---------------------------------------------------------- #\n",
    "res_test = 25\n",
    "X_lower, X_upper = 0.5, 1.5\n",
    "lin = np.linspace(X_lower, X_upper, res_test)\n",
    "nu_J1_in_test, nu_J1_out_test, nu_J23_in_test, nu_J23_out_test = np.meshgrid(lin, lin, lin, lin)\n",
    "X_test = np.array(\n",
    "    [\n",
    "        nu_J1_in_test.flatten(),\n",
    "        nu_J1_out_test.flatten(),\n",
    "        nu_J23_in_test.flatten(),\n",
    "        nu_J23_out_test.flatten(),\n",
    "    ]\n",
    ").T\n",
    "y_test = Pool(cpu_count()).map(efficiency_events, X_test)\n",
    "y_test = np.array(y_test)\n",
    "# -------------------------------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_grid(res):\n",
    "    cent_val = (X_lower + X_upper) / 2.0\n",
    "    st = (cent_val - X_lower) / 2.0\n",
    "    X_coords = np.linspace(np.repeat(X_lower, 4) + st, np.repeat(X_upper, 4) - st, res)\n",
    "    n = len(X_coords)\n",
    "    X_grid = np.ones((n * 4, 4)) * cent_val\n",
    "    for i in range(4):\n",
    "        X_grid[i * n : (i + 1) * n, i] = X_coords[:, i]\n",
    "    X_grid_set = set()\n",
    "    for x in X_grid:\n",
    "        tupl = tuple(x)\n",
    "        if tupl not in X_grid_set:\n",
    "            X_grid_set.add(tupl)\n",
    "    return np.array(list(X_grid_set))\n",
    "\n",
    "\n",
    "# -- training dataset ------------------------------------------------------ #\n",
    "X_train = generate_training_grid(res=3)\n",
    "y_train = Pool(cpu_count()).map(efficiency_events, X_train)\n",
    "y_train = np.array(y_train).reshape(\n",
    "    -1,\n",
    ")\n",
    "dX_train = X_train\n",
    "dy_train = Pool(cpu_count()).map(der_efficiency_events_sigmoid10, X_train)\n",
    "dy_train = np.array(dy_train).reshape(-1, 4)\n",
    "# -------------------------------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- utility input --------------------------------------------------------- #\n",
    "# The utility input is used to evaluate the net predictive variance of the\n",
    "# GP model at every BED iteration.\n",
    "lin = np.linspace(X_lower, X_upper, 5)\n",
    "nuJ1_in, nuJ1_out, nuJ23_in, nuJ23_out = np.meshgrid(lin, lin, lin, lin)\n",
    "X_util = np.vstack(\n",
    "    (nuJ1_in.flatten(), nuJ1_out.flatten(), nuJ23_in.flatten(), nuJ23_out.flatten())\n",
    ").T\n",
    "# -------------------------------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1**2 * RBF(length_scale=0.25) + WhiteKernel(noise_level=0.001)\n",
      "| Iter |  nu_J1_in  | nu_J1_out  | nu_J23_in  | nu_J23_out |   Target   |\n",
      "-------------------------------------------------------------------------\n",
      "|  0   |    1.25    |    1.00    |    1.00    |    1.00    |    0.96    |\n",
      "|  0   |    1.00    |    1.00    |    1.25    |    1.00    |    0.61    |\n",
      "|  0   |    1.00    |    1.00    |    0.75    |    1.00    |    0.91    |\n",
      "|  0   |    1.00    |    1.00    |    1.00    |    0.75    |    0.88    |\n",
      "|  0   |    1.00    |    1.25    |    1.00    |    1.00    |    0.98    |\n",
      "|  0   |    0.75    |    1.00    |    1.00    |    1.00    |    0.52    |\n",
      "|  0   |    1.00    |    0.75    |    1.00    |    1.00    |    0.46    |\n",
      "|  0   |    1.00    |    1.00    |    1.00    |    1.00    |    1.00    |\n",
      "|  0   |    1.00    |    1.00    |    1.00    |    1.25    |    0.64    |\n",
      "|  1   |    0.67    |    0.67    |    0.67    |    1.33    |    0.07    |\n",
      "|  2   |    1.33    |    1.33    |    1.33    |    1.33    |    1.08    |\n",
      "|  3   |    1.33    |    1.33    |    0.67    |    0.67    |    0.21    |\n",
      "|  4   |    0.67    |    0.67    |    1.33    |    0.67    |    0.07    |\n",
      "|  5   |    1.34    |    0.68    |    1.33    |    0.67    |    0.18    |\n",
      "|  6   |    0.68    |    1.34    |    0.67    |    1.33    |    0.20    |\n",
      "|  7   |    1.34    |    0.68    |    0.67    |    1.33    |    0.19    |\n",
      "|  8   |    0.68    |    1.34    |    1.33    |    0.67    |    0.21    |\n",
      "|  9   |    0.68    |    0.68    |    0.66    |    0.66    |    0.58    |\n",
      "|  10  |    0.68    |    0.68    |    1.34    |    1.34    |    0.00    |\n"
     ]
    }
   ],
   "source": [
    "# -- fitting the GP model and hyperparameter optimization ------------------ #\n",
    "kernel = RegularKernel(amplitude=0.1, length_scale=0.25, noise_level=1e-3)\n",
    "# set optimizer=None to skip optimization\n",
    "gp_reg = GaussianProcessRegressor(kernel=kernel, optimizer=None, random_state=42)\n",
    "gp_reg.fit(X_train, y_train)\n",
    "print(gp_reg.kernel)\n",
    "# -------------------------------------------------------------------------- #\n",
    "\n",
    "# -- BED ------------------------------------------------------------------- #\n",
    "BED_reg = GPUncertaintyOptimizer(\n",
    "    gp_model=gp_reg,\n",
    "    bounds={\n",
    "        \"nu_J1_in\": (X_lower, X_upper),\n",
    "        \"nu_J1_out\": (X_lower, X_upper),\n",
    "        \"nu_J23_in\": (X_lower, X_upper),\n",
    "        \"nu_J23_out\": (X_lower, X_upper),\n",
    "    },\n",
    "    function=efficiency_events,\n",
    "    random_state=42,\n",
    "    verbose=True,\n",
    ")\n",
    "gp_reg = BED_reg.minimize_variance(\n",
    "    X_util=X_util, n_iters=10, n_restarts_optimizer=10, added_noise=None\n",
    ")\n",
    "# -------------------------------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivative GP regression\n",
    "\n",
    "We also use the BED strategy to select 30 new training samples for the derivative GP model from the derivative_GP_regression notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- training dataset ------------------------------------------------------ #\n",
    "dy_train = Pool(cpu_count()).map(der_efficiency_events_sigmoid10, X_train)\n",
    "dy_train = np.array(dy_train)\n",
    "# -------------------------------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1**2 * DerivativeRBF(length_scale=0.25) + WhiteKernel(noise_level=0.001) + WhiteKernel_der(noise_level=1)\n",
      "| Iter |  nu_J1_in  | nu_J1_out  | nu_J23_in  | nu_J23_out |   Target   |\n",
      "-------------------------------------------------------------------------\n",
      "|  0   |    1.25    |    1.00    |    1.00    |    1.00    |    0.96    |\n",
      "|  0   |    1.00    |    1.00    |    1.25    |    1.00    |    0.61    |\n",
      "|  0   |    1.00    |    1.00    |    0.75    |    1.00    |    0.91    |\n",
      "|  0   |    1.00    |    1.00    |    1.00    |    0.75    |    0.88    |\n",
      "|  0   |    1.00    |    1.25    |    1.00    |    1.00    |    0.98    |\n",
      "|  0   |    0.75    |    1.00    |    1.00    |    1.00    |    0.52    |\n",
      "|  0   |    1.00    |    0.75    |    1.00    |    1.00    |    0.46    |\n",
      "|  0   |    1.00    |    1.00    |    1.00    |    1.00    |    1.00    |\n",
      "|  0   |    1.00    |    1.00    |    1.00    |    1.25    |    0.64    |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|  1   |    0.67    |    0.67    |    0.67    |    1.33    |    0.07    |\n",
      "|  2   |    1.33    |    1.33    |    1.33    |    1.33    |    1.08    |\n",
      "|  3   |    1.33    |    0.67    |    1.33    |    0.67    |    0.19    |\n",
      "|  4   |    0.67    |    1.33    |    0.67    |    0.67    |    0.56    |\n",
      "|  5   |    1.35    |    1.32    |    0.68    |    0.68    |    0.21    |\n",
      "|  6   |    0.65    |    0.68    |    1.32    |    0.68    |    0.07    |\n",
      "|  7   |    0.65    |    1.32    |    1.32    |    1.32    |    0.17    |\n",
      "|  8   |    1.35    |    0.68    |    0.68    |    1.32    |    0.19    |\n",
      "|  9   |    1.31    |    0.66    |    1.34    |    1.34    |    0.16    |\n",
      "|  10  |    0.69    |    1.34    |    0.66    |    1.34    |    0.20    |\n"
     ]
    }
   ],
   "source": [
    "# -- fitting the GP model and hyperparameter optimization ------------------ #\n",
    "kernel = DerivativeKernel(amplitude=0.1, length_scale=0.25, noise_level=1e-3, noise_level_der=1)\n",
    "# set optimizer=None to skip optimization\n",
    "gp_der = GaussianProcessRegressor(kernel=kernel, optimizer=None, random_state=42)\n",
    "gp_der.fit(X_train, y_train, X_train, dy_train)\n",
    "print(gp_der.kernel)\n",
    "# -------------------------------------------------------------------------- #\n",
    "\n",
    "# -- BED ------------------------------------------------------------------- #\n",
    "BED_der = GPUncertaintyOptimizer(\n",
    "    gp_model=gp_der,\n",
    "    bounds={\n",
    "        \"nu_J1_in\": (X_lower, X_upper),\n",
    "        \"nu_J1_out\": (X_lower, X_upper),\n",
    "        \"nu_J23_in\": (X_lower, X_upper),\n",
    "        \"nu_J23_out\": (X_lower, X_upper),\n",
    "    },\n",
    "    function=efficiency_events,\n",
    "    der_function=der_efficiency_events_sigmoid10,\n",
    "    random_state=42,\n",
    "    verbose=True,\n",
    ")\n",
    "gp_der = BED_der.minimize_variance(\n",
    "    X_util=X_util, n_iters=10, n_restarts_optimizer=10, added_noise=None\n",
    ")\n",
    "# -------------------------------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
